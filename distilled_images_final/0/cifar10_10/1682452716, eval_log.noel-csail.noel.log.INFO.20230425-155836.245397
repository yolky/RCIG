I0425 15:58:36.829715 140100199479104 eval.py:121] 


eval_log



I0425 15:58:36.832690 140100199479104 dataset_info.py:539] Load dataset info from data/tensorflow_datasets/cifar10/3.0.2
I0425 15:58:36.835742 140100199479104 dataset_builder.py:498] Reusing dataset cifar10 (data/tensorflow_datasets/cifar10/3.0.2)
I0425 15:58:36.836298 140100199479104 dataloader.py:142] Load from data/zca/cifar10_normalize_zca.npz!
I0425 15:58:37.535438 140100199479104 logging_logger.py:49] Constructing tf.data.Dataset cifar10 for split ['train', 'test'], from data/tensorflow_datasets/cifar10/3.0.2
I0425 15:58:37.535910 140100199479104 ops.py:328] Dataset size: 50000
W0425 15:58:37.549614 140100199479104 deprecation.py:350] From /home/noel/.local/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.
Instructions for updating:
Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089
I0425 15:58:39.431222 140100199479104 ops.py:328] Dataset size: 10000
I0425 15:58:40.267217 140100199479104 dataloader.py:184] Resolution: 32
I0425 15:58:40.267746 140100199479104 dataloader.py:185] Proto Scale: {'x_proto': Array(55.425625, dtype=float32, weak_type=True)}
I0425 15:58:40.372454 140100199479104 checkpoints.py:724] Restoring checkpoint from distilled_images_final/0/cifar10_10/checkpoint_10000
I0425 15:58:40.437208 140100199479104 eval.py:178] loading config from ./configs_final/depth_3.txt
I0425 15:58:40.439716 140100199479104 eval.py:184] aug: null
aug_repeats: 0
checkpoint_iters:
- 5
- 10
- 20
- 30
- 40
- 50
- 100
- 200
- 300
- 400
- 500
- 750
- 1000
- 1250
- 1500
- 2000
- 2500
- 3000
- 4000
- 5000
- 6000
- 7000
- 8000
- 9000
- 10000
- 15000
direct_batch_sizes: !!python/tuple
- null
- null
do_precompute: false
has_bn: false
hinv_batch_size: null
img_size: 32
implicit_batch_size: null
inner_train_batch_size: null
l2_rate: 0.0005
learn_labels: true
linearize: true
max_forward_batch_size: null
max_online_steps: 100
monitor_losses: false
n_hinv_steps: 20
n_inner_steps: 20
n_max_steps_pool: 16
normal_repeats: 1
pool_learning_rate: 5.0e-05
pool_model_count: 30
pool_train_batch_size: null
proto_learning_rate: 0.003
softplus_temp: 60
test_aug: flip_color_crop_rotate_translate_cutout
use_flip: true

I0425 15:58:41.104843 140100199479104 eval.py:217] no data augmentation
